kind: ConfigMap
apiVersion: v1
metadata:
  name: etl-mapping
data:
  etlMapping.yaml: |
    mappings:
      - name: fairtox_etl
        doc_type: subject
        type: aggregator
        root: subject
        props:
          - name: submitter_id
          - name: project_id
          - name: sex
          - name: euthanasia_method
          - name: strain
        parent_props:
          - path: studies[studyID:submitter_id, organism, study_design, study_type, experimental_setting]
        nested_props:
          - name: treatment
            path: treatments
            props:
              - name: test_article_name
        aggregated_props:
          - name: _samples_count
            path: samples
            fn: count
          - name: _aliquots_count
            path: samples.aliquots
            fn: count
          - name: _flow_data_count
            path: samples.aliquots.flow_cytometry_assays.flow_datas
            fn: count
          - name: _flow_analysis_data_count
            path: samples.aliquots.flow_cytometry_assays.flow_datas.flow_analysises.flow_analysis_datas
            fn: count
          - name: _ms_raw_data_count
            path: samples.aliquots.mass_spec_assays.ms_raw_datas
            fn: count
          - name: _ms_analysed_data_count
            path: samples.aliquots.mass_spec_assays.ms_raw_datas.ms_analyses
            fn: count
          - name: _weight_measurement_count
            path: housings.diets.weight_measurements
            fn: count
          - name: _slide_image_count
            path: samples.aliquots.slides.slide_images
            fn: count
          - name: _unaligned_read_count
            path: samples.aliquots.read_groups.unaligned_reads
            fn: count
          - name: _unaligned_reads_qc_count
            path: samples.aliquots.read_groups.unaligned_reads_qcs
            fn: count
          - name: _aligned_read_count
            path: samples.aliquots.read_groups.aligned_reads
            fn: count
          - name: _aligned_reads_analyzed_data_count
            path: samples.aliquots.read_groups.aligned_reads.alignment_workflows.aligned_reads_analyzed_datas
            fn: count
        joining_props:
          - index: file
            join_on: _subject_id
            props:
              - name: data_format
                src: data_format
                fn: set
              - name: data_type
                src: data_type
                fn: set
              - name: file_name
                src: file_name
                fn: set

      - name: fairtox_file
        doc_type: file
        type: collector
        root: None
        category: data_file
        props:
          - name: object_id
          - name: md5sum
          - name: file_name
          - name: file_size
          - name: data_format
          - name: data_type
          - name: state
          - name: SRA_accession_id
        injecting_props:
          subject:
            props:
              - name: _subject_id
                src: id
                fn: set
              - name: project_id
          study:
            props:
              - name: study_submitter_id
                src: submitter_id
                fn: set
              - name: _study_id
                src: id
                fn: set
              - name: project_id
---
# gen3 job run etl ETL_FORCED TRUE
apiVersion: batch/v1
kind: Job
metadata:
  name: etl2
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: gen3job
    spec:
      shareProcessNamespace: true
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              preference:
                matchExpressions:
                  - key: karpenter.sh/capacity-type
                    operator: In
                    values:
                      - on-demand
            - weight: 99
              preference:
                matchExpressions:
                  - key: eks.amazonaws.com/capacityType
                    operator: In
                    values:
                      - ONDEMAND
      volumes:
        - name: signal-volume
          emptyDir: {}
        - name: creds-volume
          secret:
            secretName: "peregrine-dbcreds"
        - name: etl-mapping
          configMap:
            name: etl-mapping
        - name: fence-yaml
          configMap:
            name: useryaml
      containers:
        - name: gen3-spark
          imagePullPolicy: Always
          image: quay.io/cdis/gen3-spark:master
          ports:
          - containerPort: 22
          - containerPort: 9000
          - containerPort: 8030
          - containerPort: 8031
          - containerPort: 8032
          - containerPort: 7077
          livenessProbe:
            tcpSocket:
              port: 9000
            initialDelaySeconds: 10
            periodSeconds: 30
          env:
          - name: DICTIONARY_URL
            valueFrom:
              configMapKeyRef:
                name: manifest-global
                key: dictionary_url
          - name: HADOOP_URL
            value: hdfs://0.0.0.0:9000
          - name: HADOOP_HOST
            value: 0.0.0.0
          volumeMounts:
            - mountPath: /usr/share/pod
              name: signal-volume
              readOnly: true
          # imagePullPolicy: Always
          resources:
            requests:
              #cpu: 6
              #memory: 14Gi
              cpu: 4 
              memory: 10Gi
          command: ["/bin/bash" ]
          args: 
            - "-c"
            - |
              trap 'exit 0' SIGINT SIGQUIT SIGTERM
              # get /usr/local/share/ca-certificates/cdis-ca.crt into system bundle
              # ssh server sudo /etc/init.d/ssh start
              # update-ca-certificates
              python run_config.py
              hdfs namenode -format
              hdfs --daemon start namenode
              hdfs --daemon start datanode
              yarn --daemon start resourcemanager
              yarn --daemon start nodemanager
              hdfs dfsadmin -safemode leave
              hdfs dfs -mkdir /archive
              hdfs dfs -mkdir /result
              hdfs dfs -mkdir /jars
              /spark/sbin/start-all.sh
              while true; do sleep 15; done
        - name: tube
          imagePullPolicy: Never
          image: quay.io/cdis/tube:feat_helm_test_corrected
          ports:
            - containerPort: 80
          env:
            - name: DB_HOST
              valueFrom:
                secretKeyRef:
                  name: peregrine-dbcreds
                  key: host
            - name: DB_DATABASE
              valueFrom:
                secretKeyRef:
                  name: sheepdog-dbcreds
                  key: database
            - name: DB_USERNAME
              valueFrom:
                secretKeyRef:
                  name: sheepdog-dbcreds
                  key: username
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: sheepdog-dbcreds
                  key: password
            - name: DB_PORT
              valueFrom:
                secretKeyRef:
                  name: sheepdog-dbcreds
                  key: port
            - name: DB_USE_SSL
              value: "False"
            - name: DICTIONARY_URL
              valueFrom:
                configMapKeyRef:
                  name: manifest-global
                  key: dictionary_url
            - name: HADOOP_URL
              value: hdfs://localhost:9000
            - name: ES_URL
              value: gen3-elasticsearch-master
            - name: HADOOP_HOST
              value: localhost
            - name: HADOOP_CLIENT_OPTS
              value: -Xmx1g
            - name: SPARK_EXECUTOR_MEMORY
              value: 4g
            - name: SPARK_DRIVER_MEMORY
              value: 6g
            - name: ETL_FORCED
              value: "TRUE"
            - name: gen3Env
              valueFrom:
                configMapKeyRef:
                  name: manifest-global
                  key: hostname
            - name: slackWebHook
              valueFrom:
                configMapKeyRef:
                  name: global
                  key: slack_webhook
                  optional: true
          volumeMounts:
            # - name: "creds-volume"
            #   readOnly: true
            #   mountPath: "/gen3/tube/creds.json"
            #   subPath: creds.json
            # Volume to signal when to kill spark
            - mountPath: /usr/share/pod
              name: signal-volume
            - name: "etl-mapping"
              readOnly: true
              mountPath: "/gen3/tube/etlMapping.yaml"
              subPath: "etlMapping.yaml"
            - name: "fence-yaml"
              readOnly: true
              mountPath: "/gen3/tube/user.yaml"
              subPath: useryaml
          resources:
            limits:
              cpu: 2
              memory: 10Gi
          command: ["/bin/bash"]
          args:
            - "-c"
            - |
              while ! bash -c "echo >/dev/tcp/localhost/9000"; do
                echo "Spark is not ready on port 9000... waiting for 10 seconds."
                sleep 10
              done

              # Port 9000 is open, continue with the rest of the script
              echo "Port 9000 is now open. Continuing with the script..."

              echo "python run_config.py && python run_etl.py"
              
              python run_config.py && python run_etl.py
              # echo 'options use-vc' >> /etc/resolv.conf
              # if [[ $ETL_FORCED != "false" ]]; then
              #   python run_config.py && python run_etl.py --force
              # else
              #   python run_config.py && python run_etl.py
              # fi
              # exitcode=$?
              # if [[ "${slackWebHook}" != 'None' ]]; then
              #   if [[ $exitcode == 1 ]]; then
              #     curl -X POST --data-urlencode "payload={\"text\": \"JOBFAIL: ETL job on ${gen3Env}\"}" "${slackWebHook}"
              #   else
              #     curl -X POST --data-urlencode "payload={\"text\": \"SUCCESS: ETL job on ${gen3Env}\"}" "${slackWebHook}"
              #   fi
              # fi
              # echo "Exit code: $exitcode"
              # exit "$exitcode"
              # Kill sidecar and all processes
              pkill -u root
      restartPolicy: Never
